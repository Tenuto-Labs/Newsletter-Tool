<html>
  <body style="font-family: Arial, sans-serif; line-height: 1.6; color: #222; padding: 20px; background-color:#fff;">
    <h1 style="font-size: 28px; margin-bottom: 0.3em;">AI WEEKLY — Dec 26, 2025</h1>
    <p><em>Exploring AI’s leap from lab to real-world impact, evolving benchmarks, and the nuanced future of intelligence.</em></p>
    <hr>

    <h2 style="font-size: 20px; margin-top: 1em;">IN THIS ISSUE</h2>
    <ul>
      <li>AI’s transition from research to execution and its geopolitical implications</li>
      <li>Advances and debates around AI generality, world models, and benchmarks</li>
      <li>Breakthroughs in multimodal perception and medical AI applications</li>
      <li>Challenges in AI evaluation: Turing Test, Theory of Mind, and task benchmarks</li>
      <li>Emerging intellectual property norms amid AI’s rise</li>
      <li>Insights on AI’s impact on work, empathy, and societal adaptation</li>
    </ul>

    <h2 style="font-size: 20px; margin-top: 2em;">THIS WEEK’S THEMES</h2>

    <h3 style="font-size: 18px; margin-top: 1em;">1. AI Moves Beyond the Lab: Execution Is the New Frontier</h3>
    <ul>
      <li>Yann LeCun highlights 2025 as the year AI left the lab, emphasizing execution over theory, especially visible in the UAE where vision, capital, and regulation align to accelerate AI deployment.</li>
      <li>Ataraxis’s presentations at SABCS showcase AI’s tangible impact in breast cancer decision-making, with clinicians adopting AI-driven insights in practice.</li>
    </ul>
    <ul>
      <li><strong>Why it matters:</strong></li>
      <li>AI’s success now depends on real-world integration, not just research breakthroughs.</li>
      <li>Geopolitical factors and regional ecosystems are critical in shaping AI leadership.</li>
      <li>Healthcare exemplifies AI’s potential for precision and empathy, improving outcomes beyond automation.</li>
    </ul>
    <ul>
      <li><strong>Voices:</strong></li>
      <li>Yann LeCun on AI execution and the Middle East’s role (<a href="https://lnkd.in/ei7qnbCY">source</a>)</li>
      <li>Ataraxis team on AI in breast cancer at SABCS (LinkedIn posts by Yann LeCun)</li>
    </ul>

    <h3 style="font-size: 18px; margin-top: 1em;">2. Rethinking AI Generality and Intelligence</h3>
    <ul>
      <li>Debates between Yann LeCun and Demis Hassabis center on the meaning of “general intelligence,” distinguishing theoretical universality from practical generality.</li>
      <li>Terence Tao’s perspective shared by LeCun suggests “artificial general cleverness” is emerging, rather than full AGI.</li>
      <li>Andrew Ng urges a nuanced understanding of LLMs — powerful yet limited — cautioning against hype around rapid AGI arrival.</li>
    </ul>
    <ul>
      <li><strong>Why it matters:</strong></li>
      <li>Clarifying AI’s capabilities helps set realistic expectations for business and policy decisions.</li>
      <li>Understanding intelligence as domain-specific informs AI system design and deployment.</li>
      <li>Distinguishing “cleverness” from “general intelligence” shapes research priorities and public discourse.</li>
    </ul>
    <ul>
      <li><strong>Voices:</strong></li>
      <li>Yann LeCun on world models and generality (<a href="https://x.com/ylecun/status/2003227257587007712">source</a>)</li>
      <li>Demis Hassabis on brain complexity and intelligence (<a href="https://x.com/demishassabis/status/2003097405026193809">source</a>)</li>
      <li>Andrew Ng on LLM strengths and limitations (LinkedIn post)</li>
      <li>Terence Tao quoted by LeCun (<a href="https://x.com/ylecun/status/2003990748564541699">source</a>)</li>
    </ul>

    <h3 style="font-size: 18px; margin-top: 1em;">3. AI Benchmarks and the Jagged Path of Progress</h3>
    <ul>
      <li>Claude 4.5 and GPT-5.1 Codex Max show remarkable gains in METR benchmark measuring autonomous task duration, with tasks growing from minutes to hours.</li>
      <li>Ethan Mollick explains how AI progress is “jagged,” with bottlenecks leading to breakthroughs like Nano Banana Pro’s unexpected impact on slide generation.</li>
      <li>High correlations among diverse benchmarks suggest AI improvements are broadly consistent across different dimensions.</li>
      <li>However, the limitations of classical tests such as the Turing Test and Theory of Mind are increasingly evident as AI surpasses them.</li>
    </ul>
    <ul>
      <li><strong>Why it matters:</strong></li>
      <li>Benchmarks guide AI development and investment but must be interpreted carefully to avoid overhyping progress in narrow domains.</li>
      <li>Understanding bottlenecks informs where to focus research and product development.</li>
      <li>Rethinking evaluation metrics is critical as AI capabilities evolve beyond traditional human-centric tests.</li>
    </ul>
    <ul>
      <li><strong>Voices:</strong></li>
      <li>Ethan Mollick on METR and AI bottlenecks (<a href="https://x.com/emollick/status/2002208335991337467">source</a>, <a href="https://lnkd.in/epPKMj69">source</a>)</li>
      <li>Mollick on Turing Test and Theory of Mind limitations (<a href="https://x.com/emollick/status/2004355265802670409">source</a>)</li>
      <li>Demis Hassabis on AI benchmarks and new apps (<a href="https://x.com/demishassabis/status/2003137379268256006">source</a>)</li>
    </ul>

    <h3 style="font-size: 18px; margin-top: 1em;">4. Multimodal Perception and Open Research Driving New AI Applications</h3>
    <ul>
      <li>Meta’s open-source Perception Encoder Audiovisual (PE-AV) advances audio-visual integration, enabling state-of-the-art audio separation and scene understanding.</li>
      <li>The Segment Anything Playground introduces interactive media segmentation tools, showcasing AI’s creative and technical utility.</li>
      <li>AI models demonstrate increasing empathy in medical text interactions, sometimes rated higher than human doctors.</li>
    </ul>
    <ul>
      <li><strong>Why it matters:</strong></li>
      <li>Multimodal AI expands the scope of AI assistance to richer, more natural interactions.</li>
      <li>Open-source tools accelerate innovation and democratize AI capabilities across sectors.</li>
      <li>Empathy in AI hints at transformative potential in healthcare and customer experience.</li>
    </ul>
    <ul>
      <li><strong>Voices:</strong></li>
      <li>Yann LeCun on PE-AV and SAM tools (<a href="https://go.meta.me/e541b6">source</a>, <a href="https://lnkd.in/gBfFvz3R">source</a>)</li>
      <li>Ethan Mollick on AI empathy in medicine (LinkedIn post)</li>
    </ul>

    <h3 style="font-size: 18px; margin-top: 1em;">5. Intellectual Property and Cultural Norms in the Age of AI</h3>
    <ul>
      <li>Ethan Mollick highlights a unique law review paper on informal intellectual property enforcement where traditional IP law fails, relevant to AI’s evolving landscape.</li>
      <li>The “clown eggs” example illustrates how communities can maintain IP norms without formal legal frameworks.</li>
    </ul>
    <ul>
      <li><strong>Why it matters:</strong></li>
      <li>AI’s rapid advancement challenges existing IP laws, requiring novel approaches to protect creators and innovators.</li>
      <li>Informal norms and community enforcement mechanisms may become increasingly important.</li>
    </ul>
    <ul>
      <li><strong>Voices:</strong></li>
      <li>Ethan Mollick on new IP protection approaches (<a href="https://lnkd.in/eBGgfjib">source</a>)</li>
    </ul>

    <h2 style="font-size: 20px; margin-top: 2em;">NOTABLE POSTS</h2>
    <ul>
      <li>Demis Hassabis cautions hobbyists about overconfidence in AI-driven scientific breakthroughs (<a href="https://x.com/fchollet/status/2002563320210157862">source</a>).</li>
      <li>Mollick shows AI can create interactive simulations to explain complex concepts like collider bias (<a href="https://lnkd.in/eY3TNH-A">source</a>).</li>
      <li>LeCun reflects on his decades-long work on world models as the foundation for AI control and planning.</li>
      <li>Mollick reports that AI’s energy use per query now matches early Google search levels, showing efficiency gains.</li>
      <li>LeCun criticizes Silicon Valley culture and political developments impacting AI and society.</li>
      <li>Mustafa Suleyman advocates building a “Humanist Superintelligence” focused on controllability and human values.</li>
      <li>Mollick emphasizes that AI is already good enough to transform work, urging proactive thinking about desired outcomes and risks.</li>
      <li>LeCun’s interview on “The Information Bottleneck” covers his new startup, critiques of AGI hype, and future visions.</li>
      <li>Mollick discusses the need for diverse, validated AI benchmarks measuring different dimensions of progress.</li>
      <li>LeCun and Hassabis engage in nuanced debates over the nature and limits of intelligence and AI capabilities.</li>
    </ul>

  </body>
</html>